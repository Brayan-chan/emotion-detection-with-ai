# ğŸ¤– Detector de Emociones con IA

[![Deployed on Vercel](https://img.shields.io/badge/Deployed%20on-Vercel-black?style=for-the-badge&logo=vercel)](https://vercel.com)
[![Next.js](https://img.shields.io/badge/Next.js-15.2.4-black?style=for-the-badge&logo=next.js)](https://nextjs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org)

## ğŸ“– DescripciÃ³n

AplicaciÃ³n web interactiva que utiliza inteligencia artificial para detectar y analizar emociones en tiempo real a travÃ©s de la cÃ¡mara web. Construida con Next.js 15, React 19 y face-api.js.

### âœ¨ CaracterÃ­sticas

- ğŸ­ **DetecciÃ³n de emociones en tiempo real**: Feliz, triste, enojado, sorprendido, disgustado, temeroso y neutral
- ğŸ¨ **Efectos visuales reactivos**: PartÃ­culas y fondos que cambian segÃºn la emociÃ³n detectada
- ğŸ”Š **RetroalimentaciÃ³n por voz**: Mensajes de audio en espaÃ±ol que responden a tus emociones
- ğŸ“Š **VisualizaciÃ³n de datos**: GrÃ¡ficos de barras con niveles de confianza para cada emociÃ³n
- ğŸ”’ **100% privado**: Todo el procesamiento ocurre en tu navegador, sin enviar datos a servidores

## ğŸš€ Despliegue en Vercel

### OpciÃ³n 1: Despliegue desde la terminal

1. **Instala Vercel CLI**:
```bash
pnpm install -g vercel
# o
npm install -g vercel
```

2. **Inicia sesiÃ³n en Vercel**:
```bash
vercel login
```

3. **Despliega la aplicaciÃ³n**:
```bash
# Para preview
vercel

# Para producciÃ³n
vercel --prod
```

### OpciÃ³n 2: Despliegue desde GitHub

1. **Sube tu cÃ³digo a GitHub** (si aÃºn no lo has hecho):
```bash
git add .
git commit -m "Preparar para despliegue en Vercel"
git push origin main
```

2. **Conecta con Vercel**:
   - Ve a [vercel.com](https://vercel.com)
   - Haz clic en "Add New..." â†’ "Project"
   - Importa tu repositorio de GitHub
   - Vercel detectarÃ¡ automÃ¡ticamente la configuraciÃ³n de Next.js
   - Haz clic en "Deploy"

### OpciÃ³n 3: BotÃ³n de despliegue rÃ¡pido

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/Brayan-chan/emotion-detection-with-ai)

## ğŸ’» Desarrollo Local

### Prerrequisitos

- Node.js 18+ 
- pnpm (recomendado) o npm

### InstalaciÃ³n

1. **Clona el repositorio**:
```bash
git clone https://github.com/Brayan-chan/emotion-detection-with-ai.git
cd emotion-detection-with-ai
```

2. **Instala las dependencias**:
```bash
pnpm install
# o
npm install
```

3. **Inicia el servidor de desarrollo**:
```bash
pnpm dev
# o
npm run dev
```

4. **Abre tu navegador** en [http://localhost:3000](http://localhost:3000)

### Scripts disponibles

```bash
pnpm dev      # Inicia el servidor de desarrollo
pnpm build    # Crea una versiÃ³n optimizada para producciÃ³n
pnpm start    # Inicia el servidor de producciÃ³n
pnpm lint     # Ejecuta el linter
```

## ğŸ› ï¸ TecnologÃ­as

- **Frontend**: Next.js 15.2, React 19, TypeScript
- **Estilos**: TailwindCSS v4, tw-animate-css
- **IA/ML**: @vladmandic/face-api.js
- **UI Components**: Radix UI
- **Analytics**: Vercel Analytics
- **GestiÃ³n de paquetes**: pnpm

## ğŸ“ Estructura del Proyecto

```
emotion-detection-with-ai/
â”œâ”€â”€ app/                      # App Router de Next.js
â”‚   â”œâ”€â”€ globals.css          # Estilos globales
â”‚   â”œâ”€â”€ layout.tsx           # Layout principal
â”‚   â””â”€â”€ page.tsx             # PÃ¡gina principal
â”œâ”€â”€ components/              # Componentes React
â”‚   â”œâ”€â”€ ai-lab-hud.tsx      # HUD estilo laboratorio
â”‚   â”œâ”€â”€ camera-feed.tsx     # Feed de la cÃ¡mara
â”‚   â”œâ”€â”€ emotion-detector.tsx # Detector principal
â”‚   â”œâ”€â”€ emotion-display.tsx  # VisualizaciÃ³n de emociones
â”‚   â”œâ”€â”€ emotion-effects.tsx  # Efectos visuales
â”‚   â””â”€â”€ emotion-voice.tsx    # SÃ­ntesis de voz
â”œâ”€â”€ lib/                     # Utilidades
â”‚   â””â”€â”€ utils.ts
â”œâ”€â”€ public/                  # Archivos estÃ¡ticos
â”œâ”€â”€ next.config.mjs          # ConfiguraciÃ³n de Next.js
â”œâ”€â”€ vercel.json             # ConfiguraciÃ³n de Vercel
â””â”€â”€ package.json            # Dependencias

```

## ğŸ”’ Privacidad y Seguridad

- âœ… Todo el anÃ¡lisis de IA se ejecuta localmente en el navegador
- âœ… No se almacenan ni transmiten imÃ¡genes o videos
- âœ… No se requiere registro ni autenticaciÃ³n
- âœ… Los modelos de IA se cargan desde CDN pÃºblico

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.

## ğŸ‘¨â€ğŸ’» Autor

**Brayan Chan**

- GitHub: [@Brayan-chan](https://github.com/Brayan-chan)

## ğŸ™ Agradecimientos

- [face-api.js](https://github.com/vladmandic/face-api) por la librerÃ­a de detecciÃ³n facial
- [v0.app](https://v0.app) por el prototipado inicial
- [Vercel](https://vercel.com) por el hosting

---

Construido con â¤ï¸ usando Next.js y face-api.js